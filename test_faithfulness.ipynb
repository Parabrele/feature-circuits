{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "parent_dir = os.path.abspath('..')\n",
    "sys.path.append(parent_dir)\n",
    "\n",
    "from nnsight import LanguageModel\n",
    "from utils import SparseAct, load_examples\n",
    "import torch as t\n",
    "import plotly.graph_objects as go\n",
    "from dictionary_learning import AutoEncoder\n",
    "from dictionary_learning.dictionary import IdentityDict\n",
    "from ablation import run_with_ablations\n",
    "from scipy import interpolate\n",
    "import math\n",
    "from statistics import stdev\n",
    "\n",
    "from circuit import get_circuit, load_circuit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ConnardMcGregoire\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\huggingface_hub\\file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "device = 'cuda:0'\n",
    "DEVICE = 'cuda:0'\n",
    "model = LanguageModel('EleutherAI/pythia-70m-deduped', device_map=device, dispatch=True)\n",
    "\n",
    "start_layer = 2 # explain the model starting here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load submodules\n",
    "submodules = []\n",
    "if start_layer < 0: submodules.append(model.gpt_neox.embed_in)\n",
    "for i in range(start_layer, len(model.gpt_neox.layers)):\n",
    "    submodules.extend([\n",
    "        model.gpt_neox.layers[i].attention,\n",
    "        model.gpt_neox.layers[i].mlp,\n",
    "        model.gpt_neox.layers[i]\n",
    "    ])\n",
    "\n",
    "submod_names = {\n",
    "    model.gpt_neox.embed_in : 'embed'\n",
    "}\n",
    "for i in range(len(model.gpt_neox.layers)):\n",
    "    submod_names[model.gpt_neox.layers[i].attention] = f'attn_{i}'\n",
    "    submod_names[model.gpt_neox.layers[i].mlp] = f'mlp_{i}'\n",
    "    submod_names[model.gpt_neox.layers[i]] = f'resid_{i}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dictionaries\n",
    "dict_id = 10\n",
    "\n",
    "activation_dim = 512\n",
    "expansion_factor = 64\n",
    "dict_size = expansion_factor * activation_dim\n",
    "\n",
    "feat_dicts = {}\n",
    "ae = AutoEncoder(activation_dim, dict_size).to(device)\n",
    "ae.load_state_dict(t.load(f\"C:/Users/ConnardMcGregoire/Documents/MI_Internship/feature-circuits/dictionary_learning/dictionaires/pythia-70m-deduped/embed/ae.pt\", map_location=device))\n",
    "feat_dicts[model.gpt_neox.embed_in] = ae\n",
    "\n",
    "d_model = activation_dim\n",
    "dict_size = d_model * expansion_factor\n",
    "\n",
    "for layer in range(len(model.gpt_neox.layers)):\n",
    "    ae = AutoEncoder(d_model, dict_size).to(device)\n",
    "    ae.load_state_dict(t.load(f\"C:/Users/ConnardMcGregoire/Documents/MI_Internship/feature-circuits/dictionary_learning/dictionaires/pythia-70m-deduped/resid_out_layer{layer}/ae.pt\", map_location=device))\n",
    "    feat_dicts[model.gpt_neox.layers[layer]] = ae\n",
    "\n",
    "    ae = AutoEncoder(d_model, dict_size).to(device)\n",
    "    ae.load_state_dict(t.load(f\"C:/Users/ConnardMcGregoire/Documents/MI_Internship/feature-circuits/dictionary_learning/dictionaires/pythia-70m-deduped/attn_out_layer{layer}/ae.pt\", map_location=device))\n",
    "    feat_dicts[model.gpt_neox.layers[layer].attention] = ae\n",
    "\n",
    "    ae = AutoEncoder(d_model, dict_size).to(device)\n",
    "    ae.load_state_dict(t.load(f\"C:/Users/ConnardMcGregoire/Documents/MI_Internship/feature-circuits/dictionary_learning/dictionaires/pythia-70m-deduped/mlp_out_layer{layer}/ae.pt\", map_location=device))\n",
    "    feat_dicts[model.gpt_neox.layers[layer].mlp] = ae\n",
    "\n",
    "neuron_dicts = {\n",
    "    submod : IdentityDict(activation_dim).to(device) for submod in submodules\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "pythia70m = model\n",
    "\n",
    "pythia70m_embed = pythia70m.gpt_neox.embed_in\n",
    "\n",
    "pythia70m_resids= []\n",
    "pythia70m_attns = []\n",
    "pythia70m_mlps = []\n",
    "for layer in range(len(pythia70m.gpt_neox.layers)):\n",
    "    pythia70m_resids.append(pythia70m.gpt_neox.layers[layer])\n",
    "    pythia70m_attns.append(pythia70m.gpt_neox.layers[layer].attention)\n",
    "    pythia70m_mlps.append(pythia70m.gpt_neox.layers[layer].mlp)\n",
    "    \n",
    "dictionaries = {}\n",
    "\n",
    "d_model = 512\n",
    "dict_size = 32768\n",
    "\n",
    "path = \"C:/Users/ConnardMcGregoire/Documents/MI_Internship/feature-circuits/dictionary_learning/dictionaires/pythia-70m-deduped/\"\n",
    "\n",
    "ae = AutoEncoder(d_model, dict_size).to(DEVICE)\n",
    "ae.load_state_dict(t.load(path + f\"embed/ae.pt\", map_location=DEVICE))\n",
    "dictionaries[pythia70m_embed] = ae\n",
    "\n",
    "\n",
    "for layer in range(len(pythia70m.gpt_neox.layers)):\n",
    "    ae = AutoEncoder(d_model, dict_size).to(DEVICE)\n",
    "    ae.load_state_dict(t.load(path + f\"resid_out_layer{layer}/ae.pt\", map_location=DEVICE))\n",
    "    dictionaries[pythia70m_resids[layer]] = ae\n",
    "\n",
    "    ae = AutoEncoder(d_model, dict_size).to(DEVICE)\n",
    "    ae.load_state_dict(t.load(path + f\"attn_out_layer{layer}/ae.pt\", map_location=DEVICE))\n",
    "    dictionaries[pythia70m_attns[layer]] = ae\n",
    "\n",
    "    ae = AutoEncoder(d_model, dict_size).to(DEVICE)\n",
    "    ae.load_state_dict(t.load(path + f\"mlp_out_layer{layer}/ae.pt\", map_location=DEVICE))\n",
    "    dictionaries[pythia70m_mlps[layer]] = ae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def metric_fn_v1(model, trg=None):\n",
    "    \"\"\"\n",
    "    default : return the logit\n",
    "    \"\"\"\n",
    "    if trg is None:\n",
    "        raise ValueError(\"trg must be provided\")\n",
    "    logits = model.embed_out.output[:,-1,:]\n",
    "    return logits[0, trg[0]] - logits[0, trg[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean = \"When Mary and John went to the store, John gave a drink to\"\n",
    "patch = \"When Mary and John went to the store, Alice gave a drink to\"\n",
    "trg = \" Mary\"\n",
    "trg_idx = t.tensor(pythia70m.tokenizer.encode(trg)[0], device=DEVICE)\n",
    "patch_trg_idx = t.tensor([253], device=DEVICE) # the"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# circuit = get_circuit(\n",
    "#     clean, patch,\n",
    "#     model,\n",
    "#     pythia70m_embed, pythia70m_attns, pythia70m_mlps, pythia70m_resids, dictionaries,\n",
    "#     metric_fn_v1, {\"trg\": (trg_idx, patch_trg_idx)}\n",
    "# )\n",
    "\n",
    "node_threshold = 0.1\n",
    "edge_threshold = 0.01\n",
    "n = 144\n",
    "\n",
    "circuit = load_circuit(\n",
    "    \"C:/Users/ConnardMcGregoire/Documents/MI_Internship/feature-circuits/circuits/\",\n",
    "    \"wikipedia3\",\n",
    "    \"pythia_70m_deduped\",\n",
    "    node_threshold,\n",
    "    edge_threshold,\n",
    "    n\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "nodes = t.empty(0)\n",
    "for k, v in circuit[0].items():\n",
    "    if k != 'y':\n",
    "        v = v.to_tensor().cpu()\n",
    "        nz = v.nonzero().squeeze()\n",
    "        nodes = t.cat((nodes, v[nz]))\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "plt.hist(nodes[nodes.abs() > 10], bins=100)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a GPTNeoXTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 50304])\n",
      "0.1829976737499237\n",
      "253\n",
      " the\n",
      "0.07211925834417343\n",
      "617\n",
      " her\n",
      "0.05171777307987213\n",
      "731\n",
      " them\n",
      "0.03711021691560745\n",
      "6393\n",
      " Mary\n",
      "0.03526845946907997\n",
      "779\n",
      " him\n",
      "0.03157972916960716\n",
      "16922\n",
      " Alice\n",
      "0.0294966921210289\n",
      "247\n",
      " a\n",
      "0.011895938776433468\n",
      "5332\n",
      " Jack\n",
      "0.011458381079137325\n",
      "616\n",
      " their\n",
      "0.008285464718937874\n",
      "521\n",
      " his\n"
     ]
    }
   ],
   "source": [
    "with model.trace(patch):\n",
    "    logits = model.output.save()\n",
    "\n",
    "print(logits[0][:, -1, :].shape)\n",
    "logits = logits[0][:, -1, :].squeeze()\n",
    "perm = t.argsort(logits, descending=True)\n",
    "p = t.softmax(logits, dim=-1)\n",
    "for i in range(10):\n",
    "    print(p[perm[i].item()].item())\n",
    "    print(perm[i].item())\n",
    "    print(pythia70m.tokenizer.decode([perm[i].item()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use mean ablation\n",
    "ablation_fn = lambda x: x.mean(dim=0).expand_as(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get m(C) for the circuit obtained by thresholding nodes with the given threshold\n",
    "def get_fcs(\n",
    "    model,\n",
    "    circuit,\n",
    "    submodules,\n",
    "    dictionaries,\n",
    "    ablation_fn,\n",
    "    thresholds,\n",
    "    handle_errors = 'default', # also 'remove' or 'resid_only'\n",
    "):\n",
    "    clean_inputs = clean\n",
    "    clean_answer_idxs = trg_idx\n",
    "    patch_inputs = patch\n",
    "    patch_answer_idxs = patch_trg_idx\n",
    "\n",
    "    def metric_fn(model):\n",
    "        return (\n",
    "            - t.gather(model.embed_out.output[:,-1,:], dim=-1, index=patch_answer_idxs.view(-1, 1)).squeeze(-1) + \\\n",
    "            t.gather(model.embed_out.output[:,-1,:], dim=-1, index=clean_answer_idxs.view(-1, 1)).squeeze(-1)\n",
    "        )\n",
    "    \n",
    "    circuit = circuit[0]\n",
    "\n",
    "    with t.no_grad():\n",
    "        out = {}\n",
    "\n",
    "        # get F(M)\n",
    "        with model.trace(clean_inputs):\n",
    "            metric = metric_fn(model).save()\n",
    "        fm = metric.value.mean().item()\n",
    "\n",
    "        out['fm'] = fm\n",
    "\n",
    "        # get m(∅)\n",
    "        fempty = run_with_ablations(\n",
    "            clean_inputs,\n",
    "            patch_inputs,\n",
    "            model,\n",
    "            submodules,\n",
    "            dictionaries,\n",
    "            nodes = {\n",
    "                submod : SparseAct(\n",
    "                    act=t.zeros(dict_size, dtype=t.bool), \n",
    "                    resc=t.zeros(1, dtype=t.bool)).to(device)\n",
    "                for submod in submodules\n",
    "            },\n",
    "            metric_fn=metric_fn,\n",
    "            ablation_fn=ablation_fn,\n",
    "        ).mean().item()\n",
    "        out['fempty'] = fempty\n",
    "\n",
    "        for threshold in thresholds:\n",
    "            out[threshold] = {}\n",
    "            nodes = {\n",
    "                submod : circuit[submod_names[submod]].abs() > threshold for submod in submodules\n",
    "            }\n",
    "\n",
    "            if handle_errors == 'remove':\n",
    "                for k in nodes: nodes[k].resc = t.zeros_like(nodes[k].resc, dtype=t.bool)\n",
    "            elif handle_errors == 'resid_only':\n",
    "                for k in nodes:\n",
    "                    if k not in model.gpt_neox.layers: nodes[k].resc = t.zeros_like(nodes[k].resc, dtype=t.bool)\n",
    "\n",
    "            n_nodes = sum([n.act.sum() + n.resc.sum() for n in nodes.values()]).item()\n",
    "            out[threshold]['n_nodes'] = n_nodes\n",
    "            \n",
    "            out[threshold]['fc'] = run_with_ablations(\n",
    "                clean_inputs,\n",
    "                patch_inputs,\n",
    "                model,\n",
    "                submodules,\n",
    "                dictionaries,\n",
    "                nodes=nodes,\n",
    "                metric_fn=metric_fn,\n",
    "                ablation_fn=ablation_fn,\n",
    "            ).mean().item()\n",
    "            out[threshold]['fccomp'] = run_with_ablations(\n",
    "                clean_inputs,\n",
    "                patch_inputs,\n",
    "                model,\n",
    "                submodules,\n",
    "                dictionaries,\n",
    "                nodes=nodes,\n",
    "                metric_fn=metric_fn,\n",
    "                ablation_fn=ablation_fn,\n",
    "                complement=True\n",
    "            ).mean().item()\n",
    "            out[threshold]['faithfulness'] = (out[threshold]['fc'] - fempty) / (fm - fempty)\n",
    "            out[threshold]['completeness'] = (out[threshold]['fccomp'] - fempty) / (fm - fempty)\n",
    "    \n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#thresholds = [0.001, 0.002, 0.004, 0.008, 0.016, 0.032, 0.064, 0.128, 0.256, 0.512]\n",
    "thresholds = t.logspace(-6, 2, 20, 10).tolist()\n",
    "outs = {\n",
    "    'features' :\n",
    "        get_fcs(\n",
    "            model,\n",
    "            circuit,\n",
    "            submodules,\n",
    "            feat_dicts,\n",
    "            ablation_fn=ablation_fn,\n",
    "            thresholds = thresholds,\n",
    "        ),\n",
    "    'features_wo_errs' :\n",
    "        get_fcs(\n",
    "            model,\n",
    "            circuit,\n",
    "            submodules,\n",
    "            feat_dicts,\n",
    "            ablation_fn=ablation_fn,\n",
    "            thresholds = thresholds,\n",
    "            handle_errors='remove'\n",
    "        ),\n",
    "    'features_wo_some_errs' :\n",
    "        get_fcs(\n",
    "            model,\n",
    "            circuit,\n",
    "            submodules,\n",
    "            feat_dicts,\n",
    "            ablation_fn=ablation_fn,\n",
    "            thresholds = thresholds,\n",
    "            handle_errors='resid_only'\n",
    "        )\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting: features\n",
      "Min nodes: 24\n",
      "Max nodes: 62153\n",
      "xs: [62154, 61841, 61464, 60943, 60158, 58987, 57018, 54050, 49442, 42688, 33704, 23159, 12758, 5372, 1900, 664, 228, 85, 43, 23]\n",
      "fs: [0.39124886052871466, 0.3941659070191431, 0.3392889699179581, 0.3830446672743847, 0.548404740200547, 0.48350045578851414, 0.4902461257976299, 0.5494986326344576, 0.5945305378304466, 0.64102096627165, 0.7622607110300821, 0.42424794895168644, -0.3088422971741112, -0.23482224247948952, -0.3959890610756609, -0.3436645396536007, -0.38359161349134, -0.3290793072014585, -0.3316317228805834, -0.05305378304466728]\n",
      "Setting: features_wo_errs\n",
      "Min nodes: 16\n",
      "Max nodes: 62141\n",
      "xs: [62142, 61829, 61452, 60931, 60146, 58975, 57006, 54038, 49430, 42676, 33692, 23147, 12746, 5360, 1888, 652, 216, 73, 31, 15]\n",
      "fs: [-0.8297174111212398, -0.831175934366454, -0.8884229717411122, -0.8041932543299909, -0.7941659070191431, -0.8329990884229718, -0.8160437556973564, -0.8151321786690975, -0.6807657247037374, -0.6862351868732908, -0.4813126709206928, -0.30063810391978124, -0.03263445761166819, -0.003463992707383774, 0.0018231540565177757, -0.00036463081130355516, 0.0, 0.0, 0.0, 0.0]\n",
      "Setting: features_wo_some_errs\n",
      "Min nodes: 20\n",
      "Max nodes: 62145\n",
      "xs: [62146, 61833, 61456, 60935, 60150, 58979, 57010, 54042, 49434, 42680, 33696, 23151, 12750, 5364, 1892, 656, 220, 77, 35, 19]\n",
      "fs: [0.1487693710118505, 0.15587967183226983, 0.10464904284412033, 0.15970829535095715, 0.25177757520510485, 0.14949863263445762, 0.20200546946216955, 0.2924339106654512, 0.3959890610756609, 0.23391066545123063, 0.26763901549680946, 0.12579762989972654, 0.08824065633546034, 0.060711030082041935, -0.03518687329079307, -0.035733819507748406, -0.003099361896080219, 0.05396536007292616, 0.06289881494986327, 0.06289881494986327]\n"
     ]
    }
   ],
   "source": [
    "for setting, subouts in outs.items():\n",
    "    x_min = max([min(subouts[t]['n_nodes'] for t in thresholds)]) + 1\n",
    "    x_max = min([max(subouts[t]['n_nodes'] for t in thresholds)]) - 1\n",
    "    \n",
    "    xs = [subouts[t]['n_nodes'] for t in thresholds]\n",
    "    \n",
    "    fs = [subouts[t]['faithfulness'] for t in thresholds]\n",
    "\n",
    "    print(f\"Setting: {setting}\")\n",
    "    print(f\"Min nodes: {x_min}\")\n",
    "    print(f\"Max nodes: {x_max}\")\n",
    "    print(f\"xs: {xs}\")\n",
    "    print(f\"fs: {fs}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot faithfulness results\n",
    "fig = go.Figure()\n",
    "\n",
    "colors = {\n",
    "    'features' : 'blue',\n",
    "    'features_wo_errs' : 'red',\n",
    "    'features_wo_some_errs' : 'green',\n",
    "    'neurons' : 'purple',\n",
    "    # 'random_features' : 'black'\n",
    "}\n",
    "\n",
    "y_min = 0\n",
    "y_max = 1\n",
    "for setting, subouts in outs.items():\n",
    "    x_min = max([min(subouts[t]['n_nodes'] for t in thresholds)]) + 1\n",
    "    x_max = min([max(subouts[t]['n_nodes'] for t in thresholds)]) - 1\n",
    "    fs = {\n",
    "        \"ioi\" : interpolate.interp1d([subouts[t]['n_nodes'] for t in thresholds], [subouts[t]['faithfulness'] for t in thresholds])\n",
    "    }\n",
    "    xs = t.logspace(math.log10(x_min), math.log10(x_max), 100, 10).tolist()\n",
    "\n",
    "    fig.add_trace(go.Scatter(\n",
    "        x = [subouts[t]['n_nodes'] for t in thresholds],\n",
    "        y = [subouts[t]['faithfulness'] for t in thresholds],\n",
    "        mode='lines', line=dict(color=colors[setting]), opacity=0.17, showlegend=False\n",
    "    ))\n",
    "\n",
    "    y_min = min(y_min, min([subouts[t]['faithfulness'] for t in thresholds]))\n",
    "    y_max = max(y_max, max([subouts[t]['faithfulness'] for t in thresholds]))\n",
    "\n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=xs,\n",
    "        y=[ sum([f(x) for f in fs.values()]) / len(fs) for x in xs ],\n",
    "        mode='lines', line=dict(color=colors[setting]), name=setting\n",
    "    ))\n",
    "\n",
    "fig.update_xaxes(type=\"log\", range=[math.log10(x_min), math.log10(x_max)])\n",
    "fig.update_yaxes(range=[y_min, y_max])\n",
    "\n",
    "fig.update_layout(\n",
    "    xaxis_title='Nodes',\n",
    "    yaxis_title='Faithfulness',\n",
    "    width=800,\n",
    "    height=375,\n",
    "    # set white background color\n",
    "    plot_bgcolor='rgba(0,0,0,0)',\n",
    "    # add grey gridlines\n",
    "    yaxis=dict(gridcolor='rgb(200,200,200)',mirror=True,ticks='outside',showline=True),\n",
    "    xaxis=dict(gridcolor='rgb(200,200,200)', mirror=True, ticks='outside', showline=True),\n",
    "\n",
    ")\n",
    "\n",
    "# fig.show()\n",
    "fig.write_image('faithfulness.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'datasets' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[31], line 13\u001b[0m\n\u001b[0;32m      4\u001b[0m colors \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m      5\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfeatures\u001b[39m\u001b[38;5;124m'\u001b[39m : \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mblue\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m      6\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfeatures_wo_errs\u001b[39m\u001b[38;5;124m'\u001b[39m : \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mred\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m      7\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfeatures_wo_some_errs\u001b[39m\u001b[38;5;124m'\u001b[39m : \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgreen\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m      8\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mneurons\u001b[39m\u001b[38;5;124m'\u001b[39m : \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpurple\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m      9\u001b[0m }\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m setting, subouts \u001b[38;5;129;01min\u001b[39;00m outs\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m---> 13\u001b[0m     x_min \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmax\u001b[39m([\u001b[38;5;28mmin\u001b[39m(subouts[dataset][t][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mn_nodes\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m thresholds) \u001b[38;5;28;01mfor\u001b[39;00m dataset \u001b[38;5;129;01min\u001b[39;00m \u001b[43mdatasets\u001b[49m]) \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m     14\u001b[0m     x_max \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmin\u001b[39m([\u001b[38;5;28mmax\u001b[39m(subouts[dataset][t][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mn_nodes\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m thresholds) \u001b[38;5;28;01mfor\u001b[39;00m dataset \u001b[38;5;129;01min\u001b[39;00m datasets]) \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m     15\u001b[0m     fs \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m     16\u001b[0m         dataset : interpolate\u001b[38;5;241m.\u001b[39minterp1d([subouts[dataset][t][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mn_nodes\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m thresholds], [subouts[dataset][t][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcompleteness\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m thresholds])\n\u001b[0;32m     17\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m dataset \u001b[38;5;129;01min\u001b[39;00m datasets\n\u001b[0;32m     18\u001b[0m     }\n",
      "\u001b[1;31mNameError\u001b[0m: name 'datasets' is not defined"
     ]
    }
   ],
   "source": [
    "# plot completeness results\n",
    "fig = go.Figure()\n",
    "\n",
    "colors = {\n",
    "    'features' : 'blue',\n",
    "    'features_wo_errs' : 'red',\n",
    "    'features_wo_some_errs' : 'green',\n",
    "    'neurons' : 'purple'\n",
    "}\n",
    "\n",
    "for setting, subouts in outs.items():\n",
    "\n",
    "    x_min = max([min(subouts[dataset][t]['n_nodes'] for t in thresholds) for dataset in datasets]) + 1\n",
    "    x_max = min([max(subouts[dataset][t]['n_nodes'] for t in thresholds) for dataset in datasets]) - 1\n",
    "    fs = {\n",
    "        dataset : interpolate.interp1d([subouts[dataset][t]['n_nodes'] for t in thresholds], [subouts[dataset][t]['completeness'] for t in thresholds])\n",
    "        for dataset in datasets\n",
    "    }\n",
    "    xs = t.logspace(math.log10(x_min), math.log10(x_max), 100, 10).tolist()\n",
    "\n",
    "    for dataset in datasets:\n",
    "        fig.add_trace(go.Scatter(\n",
    "            x = [subouts[dataset][t]['n_nodes'] for t in thresholds],\n",
    "            y = [subouts[dataset][t]['completeness'] for t in thresholds],\n",
    "            mode='lines', line=dict(color=colors[setting]), opacity=0.17, showlegend=False\n",
    "        ))\n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=xs,\n",
    "        y=[ sum([f(x) for f in fs.values()]) / len(fs) for x in xs ],\n",
    "        mode='lines', line=dict(color=colors[setting]), name=setting\n",
    "    ))\n",
    "\n",
    "fig.update_xaxes(range=(0,300))\n",
    "fig.update_yaxes(range=(-.15, 1))\n",
    "\n",
    "fig.update_layout(\n",
    "    xaxis_title='Nodes',\n",
    "    yaxis_title='Faithfulness',\n",
    "    width=800,\n",
    "    height=375,\n",
    "    # set white background color\n",
    "    plot_bgcolor='rgba(0,0,0,0)',\n",
    "    # add grey gridlines\n",
    "    yaxis=dict(gridcolor='rgb(200,200,200)',mirror=True,ticks='outside',showline=True),\n",
    "    xaxis=dict(gridcolor='rgb(200,200,200)', mirror=True, ticks='outside', showline=True),\n",
    ")\n",
    "# fig.show()\n",
    "fig.write_image('completeness.pdf')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
