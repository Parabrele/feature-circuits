{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ConnardMcGregoire\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEVICE : cuda:0\n",
      "IN_COLAB : False\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Get the general graph of a given model\n",
    "\n",
    "Algorithm :\n",
    "Get model & dicts\n",
    "Get circuit fct\n",
    "aggregate graphs over dataset\n",
    "test this graph on dataset\n",
    "\n",
    "TODO : get circuit fct is wrong from marks\n",
    "TODO : test graph is wrong from marks (but eh, it will yield better results as we will\n",
    "       have essentially the whole graph, but hush, don't say it ! :o)\n",
    "\"\"\"\n",
    "\n",
    "try:\n",
    "    import google.colab\n",
    "    IN_COLAB = True\n",
    "    from tqdm.notebook import tqdm, trange\n",
    "\n",
    "    from google.colab import drive\n",
    "    drive.mount(\"/content/gdrive\", force_remount=True)\n",
    "    %cd /content/gdrive/MyDrive/feature-circuits\n",
    "    %pip install -r requirements.txt\n",
    "    !git submodule update --init\n",
    "except:\n",
    "    IN_COLAB = False\n",
    "    from tqdm import tqdm, trange\n",
    "\n",
    "import os\n",
    "import gc\n",
    "\n",
    "from transformers import logging\n",
    "logging.set_verbosity_error()\n",
    "\n",
    "import torch\n",
    "from nnsight import LanguageModel\n",
    "from datasets import load_dataset\n",
    "\n",
    "from dictionary_learning import AutoEncoder\n",
    "from utils import SparseAct\n",
    "from buffer import TokenBuffer\n",
    "from circuit import get_circuit, save_circuit, load_circuit\n",
    "from ablation import run_with_ablations\n",
    "\n",
    "DEVICE = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
    "print(\"DEVICE :\", DEVICE)\n",
    "\n",
    "print(\"IN_COLAB :\", IN_COLAB)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First step : generate the graph\n",
    "\n",
    "compute the circuit for random examples from wikipedia, and aggregate the results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO : move tokensbuffer in a separate file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ConnardMcGregoire\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\huggingface_hub\\file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "pythia70m = LanguageModel(\n",
    "    \"EleutherAI/pythia-70m-deduped\",\n",
    "    device_map=DEVICE,\n",
    "    dispatch=True,\n",
    ")\n",
    "\n",
    "pythia70m_embed = pythia70m.gpt_neox.embed_in\n",
    "\n",
    "pythia70m_resids= []\n",
    "pythia70m_attns = []\n",
    "pythia70m_mlps = []\n",
    "for layer in range(len(pythia70m.gpt_neox.layers)):\n",
    "    pythia70m_resids.append(pythia70m.gpt_neox.layers[layer])\n",
    "    pythia70m_attns.append(pythia70m.gpt_neox.layers[layer].attention)\n",
    "    pythia70m_mlps.append(pythia70m.gpt_neox.layers[layer].mlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_dataset(\n",
    "    \"wikipedia\",\n",
    "    language=\"en\",\n",
    "    date=\"20240401\",\n",
    "    split=\"train\",\n",
    "    streaming=True,\n",
    "    trust_remote_code=True\n",
    ").shuffle()\n",
    "dataset = iter(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "buffer = TokenBuffer(\n",
    "    dataset,\n",
    "    pythia70m,\n",
    "    n_ctxs=10,\n",
    "    ctx_len=16,\n",
    "    load_buffer_batch_size=10,\n",
    "    return_batch_size=10,\n",
    "    device=DEVICE,\n",
    "    max_number_of_yields=2**20,\n",
    "    discard_bos=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "if IN_COLAB:\n",
    "    base = \"/content/gdrive/MyDrive/feature-circuits/\"\n",
    "else:\n",
    "    #base = \"C:/Users/Grégoire/Documents/ENS/stages/AttentionGraph/Marks/feature-circuits/\"\n",
    "    base = 'C:/Users/ConnardMcGregoire/Documents/MI_Internship/feature-circuits/'\n",
    "path = base + \"dictionary_learning/dictionaires/pythia-70m-deduped/\"\n",
    "\n",
    "if not os.path.exists(path):\n",
    "    if IN_COLAB:\n",
    "        # go to base / dictionary_learning :\n",
    "        %cd /content/gdrive/MyDrive/feature-circuits/dictionary_learning\n",
    "        !apt-get update\n",
    "        !apt-get install dos2unix\n",
    "        !dos2unix pretrained_dictionary_downloader.sh\n",
    "        !chmod +x pretrained_dictionary_downloader.sh\n",
    "        !./pretrained_dictionary_downloader.sh\n",
    "        %cd /content/gdrive/MyDrive/feature-circuits\n",
    "    else:\n",
    "        #%cd C:/Users/Grégoire/Documents/ENS/stages/AttentionGraph/Marks/feature-circuits/dictionary_learning\n",
    "        %cd C:/Users/ConnardMcGregoire/Documents/MI_Internship/feature-circuits/dictionary_learning\n",
    "        %run ./pretrained_dictionary_downloader.sh\n",
    "        #%cd C:/Users/Grégoire/Documents/ENS/stages/AttentionGraph/Marks/feature-circuits\n",
    "        %cd C:/Users/ConnardMcGregoire/Documents/MI_Internship/feature-circuits\n",
    "\n",
    "dictionaries = {}\n",
    "\n",
    "d_model = 512\n",
    "dict_size = 32768\n",
    "\n",
    "ae = AutoEncoder(d_model, dict_size).to(DEVICE)\n",
    "ae.load_state_dict(torch.load(path + f\"embed/ae.pt\", map_location=DEVICE))\n",
    "dictionaries[pythia70m_embed] = ae\n",
    "\n",
    "\n",
    "for layer in range(len(pythia70m.gpt_neox.layers)):\n",
    "    ae = AutoEncoder(d_model, dict_size).to(DEVICE)\n",
    "    ae.load_state_dict(torch.load(path + f\"resid_out_layer{layer}/ae.pt\", map_location=DEVICE))\n",
    "    dictionaries[pythia70m_resids[layer]] = ae\n",
    "\n",
    "    ae = AutoEncoder(d_model, dict_size).to(DEVICE)\n",
    "    ae.load_state_dict(torch.load(path + f\"attn_out_layer{layer}/ae.pt\", map_location=DEVICE))\n",
    "    dictionaries[pythia70m_attns[layer]] = ae\n",
    "\n",
    "    ae = AutoEncoder(d_model, dict_size).to(DEVICE)\n",
    "    ae.load_state_dict(torch.load(path + f\"mlp_out_layer{layer}/ae.pt\", map_location=DEVICE))\n",
    "    dictionaries[pythia70m_mlps[layer]] = ae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def metric_fn_v1(model, trg=None):\n",
    "    \"\"\"\n",
    "    default : return the logit\n",
    "    \"\"\"\n",
    "    if trg is None:\n",
    "        raise ValueError(\"trg must be provided\")\n",
    "    logits = model.embed_out.output[:,-1,:]\n",
    "    return logits[torch.arange(trg.numel()), trg]\n",
    "    \n",
    "def metric_fn_v2(model, trg=None):\n",
    "    \"\"\"\n",
    "    default : return the logit\n",
    "    \"\"\"\n",
    "    if trg is None:\n",
    "        raise ValueError(\"trg must be provided\")\n",
    "    return model.embed_out.output[torch.arange(trg[0].numel()), trg[0], trg[1]]\n",
    "\n",
    "def metric_fn_v3(model, trg=None):\n",
    "    \"\"\"\n",
    "    Return -log probability for the expected target.\n",
    "\n",
    "    trg : torch.Tensor, contains idxs of the target tokens (between 0 and d_vocab_out)\n",
    "\n",
    "    /!\\ here we assume that all last tokens are indeed in the last position (if padding, it must happen in front of the sequence, not after)\n",
    "    \"\"\"\n",
    "    if trg is None:\n",
    "        raise ValueError(\"trg must be provided\")\n",
    "    logits = model.embed_out.output[:,-1,:]\n",
    "    return (\n",
    "         -1 * torch.gather(\n",
    "             torch.nn.functional.log_softmax(model.embed_out.output[:,-1,:], dim=-1),\n",
    "             dim=-1, index=trg.view(-1, 1)\n",
    "         ).squeeze(-1)\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO : if multiple GPUS, use nn.DataParallel and compute batches of length num_gpus. Each GPU will compute one input. Maybe DistributedDataParallel is better.\n",
    "\n",
    "Or : launch N instances of the code that work independently on random inputs, each on their own GPU, save the circuits in a file and then process 0 is in charge of aggregating the results. If torch provide multiprocessing communications, this can be done without storing to the disc. Then process 0 sends to all the others the final circuits, they all test it and aggregate the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting content from https://dumps.wikimedia.org/enwiki/20240401/enwiki-20240401-pages-articles-multistream23.xml-p49288942p50564553.bz2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:26, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "tot_circuit = None\n",
    "i = 0\n",
    "max_loop = -1\n",
    "edge_threshold = 0.01\n",
    "node_threshold = 0.1\n",
    "\n",
    "for tokens, trg_idx, trg in tqdm(buffer):\n",
    "    if i >= max_loop:\n",
    "        break\n",
    "    i += 1\n",
    "    circuit = get_circuit(\n",
    "        tokens,\n",
    "        None,\n",
    "        model=pythia70m,\n",
    "        embed=pythia70m_embed,\n",
    "        attns=pythia70m_attns,\n",
    "        mlps=pythia70m_mlps,\n",
    "        resids=pythia70m_resids,\n",
    "        dictionaries=dictionaries,\n",
    "        metric_fn=metric_fn_v2,\n",
    "        metric_kwargs={\"trg\": (trg_idx, trg)},\n",
    "        node_threshold=node_threshold,\n",
    "        edge_threshold=edge_threshold\n",
    "    )\n",
    "    if tot_circuit is None:\n",
    "        tot_circuit = circuit\n",
    "    else:\n",
    "        for k, v in circuit[0].items():\n",
    "            if v is not None:\n",
    "                tot_circuit[0][k] += v\n",
    "        for ku, vu in circuit[1].items():\n",
    "            for kd, vd in vu.items():\n",
    "                if vd is not None:\n",
    "                    tot_circuit[1][ku][kd] += vd\n",
    "    \n",
    "    if i % 16 == 0:\n",
    "        save_circuit(\n",
    "            \"C:/Users/ConnardMcGregoire/Documents/MI_Internship/feature-circuits/circuits/\",\n",
    "            tot_circuit[0],\n",
    "            tot_circuit[1],\n",
    "            \"wikipedia3\",\n",
    "            \"pythia_70m_deduped\",\n",
    "            node_threshold,\n",
    "            edge_threshold,\n",
    "            i\n",
    "        )\n",
    "    \n",
    "    del circuit\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO : test general circuit on IOI task and on general task. Plot avg degree of nodes when pruning the graph for reach and co reach for node threshold / node proportion for graph build upon 1 2 4 8 [i * 16]_i=1^10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "submod_names = {\n",
    "    pythia70m.gpt_neox.embed_in : 'embed'\n",
    "}\n",
    "for i in range(len(pythia70m.gpt_neox.layers)):\n",
    "    submod_names[pythia70m.gpt_neox.layers[i].attention] = f'attn_{i}'\n",
    "    submod_names[pythia70m.gpt_neox.layers[i].mlp] = f'mlp_{i}'\n",
    "    submod_names[pythia70m.gpt_neox.layers[i]] = f'resid_{i}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 144\n",
    "\n",
    "circuit = load_circuit(\n",
    "    \"C:/Users/ConnardMcGregoire/Documents/MI_Internship/feature-circuits/circuits/\",\n",
    "    \"wikipedia3\",\n",
    "    \"pythia_70m_deduped\",\n",
    "    node_threshold,\n",
    "    edge_threshold,\n",
    "    n\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_at_layer = 2\n",
    "submodules = [pythia70m_embed] if start_at_layer == 0 else []\n",
    "for i in range(start_at_layer, len(pythia70m.gpt_neox.layers)):\n",
    "    submodules.append(pythia70m_attns[i])\n",
    "    submodules.append(pythia70m_mlps[i])\n",
    "    submodules.append(pythia70m_resids[i])\n",
    "\n",
    "feat_dicts = dictionaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use mean ablation\n",
    "\n",
    "\n",
    "import importlib\n",
    "import ablation\n",
    "importlib.reload(ablation)\n",
    "from ablation import run_with_ablations\n",
    "\n",
    "ablation_fn = lambda x: x.mean(dim=0).expand_as(x)\n",
    "\n",
    "# get m(C) for the circuit obtained by thresholding nodes with the given threshold\n",
    "def get_fcs(\n",
    "    model,\n",
    "    circuit,\n",
    "    clean,\n",
    "    trg_idx,\n",
    "    trg,\n",
    "    submodules,\n",
    "    dictionaries,\n",
    "    ablation_fn,\n",
    "    thresholds,\n",
    "    handle_errors = 'default', # also 'remove' or 'resid_only'\n",
    "):\n",
    "    clean_inputs = clean\n",
    "\n",
    "    # def metric_fn(model):\n",
    "    #     return (\n",
    "    #         - t.gather(model.embed_out.output[:,-1,:], dim=-1, index=patch_answer_idxs.view(-1, 1)).squeeze(-1) + \\\n",
    "    #         t.gather(model.embed_out.output[:,-1,:], dim=-1, index=clean_answer_idxs.view(-1, 1)).squeeze(-1)\n",
    "    #     )\n",
    "    def metric_fn(model):\n",
    "        return metric_fn_v2(model, trg=(trg_idx, trg))\n",
    "    \n",
    "    circuit = circuit[0]\n",
    "\n",
    "    with torch.no_grad():\n",
    "        out = {}\n",
    "\n",
    "        # get F(M)\n",
    "        with model.trace(clean_inputs):\n",
    "            metric = metric_fn(model).save()\n",
    "        fm = metric.value.mean().item()\n",
    "\n",
    "        out['fm'] = fm\n",
    "\n",
    "        # get m(∅)\n",
    "        fempty = run_with_ablations(\n",
    "            clean_inputs,\n",
    "            None,\n",
    "            model,\n",
    "            submodules,\n",
    "            dictionaries,\n",
    "            nodes = {\n",
    "                submod : SparseAct(\n",
    "                    act=torch.zeros(dict_size, dtype=torch.bool), \n",
    "                    resc=torch.zeros(1, dtype=torch.bool)).to(DEVICE)\n",
    "                for submod in submodules\n",
    "            },\n",
    "            metric_fn=metric_fn,\n",
    "            ablation_fn=ablation_fn,\n",
    "        ).mean().item()\n",
    "        out['fempty'] = fempty\n",
    "\n",
    "        for threshold in thresholds:\n",
    "            out[threshold] = {}\n",
    "            nodes = {\n",
    "                submod : circuit[submod_names[submod]].abs() > threshold for submod in submodules\n",
    "            }\n",
    "\n",
    "            if handle_errors == 'remove':\n",
    "                for k in nodes: nodes[k].resc = torch.zeros_like(nodes[k].resc, dtype=torch.bool)\n",
    "            elif handle_errors == 'resid_only':\n",
    "                for k in nodes:\n",
    "                    if k not in model.gpt_neox.layers: nodes[k].resc = torch.zeros_like(nodes[k].resc, dtype=torch.bool)\n",
    "\n",
    "            n_nodes = sum([n.act.sum() + n.resc.sum() for n in nodes.values()]).item()\n",
    "            out[threshold]['n_nodes'] = n_nodes\n",
    "            \n",
    "            out[threshold]['fc'] = run_with_ablations(\n",
    "                clean_inputs,\n",
    "                None,\n",
    "                model,\n",
    "                submodules,\n",
    "                dictionaries,\n",
    "                nodes=nodes,\n",
    "                metric_fn=metric_fn,\n",
    "                ablation_fn=ablation_fn,\n",
    "            ).mean().item()\n",
    "            out[threshold]['fccomp'] = run_with_ablations(\n",
    "                clean_inputs,\n",
    "                None,\n",
    "                model,\n",
    "                submodules,\n",
    "                dictionaries,\n",
    "                nodes=nodes,\n",
    "                metric_fn=metric_fn,\n",
    "                ablation_fn=ablation_fn,\n",
    "                complement=True\n",
    "            ).mean().item()\n",
    "            out[threshold]['faithfulness'] = (out[threshold]['fc'] - fempty) / (fm - fempty)\n",
    "            out[threshold]['completeness'] = (out[threshold]['fccomp'] - fempty) / (fm - fempty)\n",
    "    \n",
    "    print(\"the end\")\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the end\n",
      "the end\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [02:03, 123.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the end\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "max_loop = 1\n",
    "\n",
    "for tokens, trg_idx, trg in tqdm(buffer):\n",
    "    if i >= max_loop:\n",
    "        break\n",
    "    i += 1\n",
    "    #thresholds = [0.001, 0.002, 0.004, 0.008, 0.016, 0.032, 0.064, 0.128, 0.256, 0.512]\n",
    "    thresholds = torch.logspace(-6, 2, 20, 10).tolist()\n",
    "    outs = {\n",
    "        'features' :\n",
    "            get_fcs(\n",
    "                pythia70m,\n",
    "                circuit,\n",
    "                tokens,\n",
    "                trg_idx,\n",
    "                trg,\n",
    "                submodules,\n",
    "                feat_dicts,\n",
    "                ablation_fn=ablation_fn,\n",
    "                thresholds = thresholds,\n",
    "            ),\n",
    "        'features_wo_errs' :\n",
    "            get_fcs(\n",
    "                pythia70m,\n",
    "                circuit,\n",
    "                tokens,\n",
    "                trg_idx,\n",
    "                trg,\n",
    "                submodules,\n",
    "                feat_dicts,\n",
    "                ablation_fn=ablation_fn,\n",
    "                thresholds = thresholds,\n",
    "                handle_errors='remove'\n",
    "            ),\n",
    "        'features_wo_some_errs' :\n",
    "            get_fcs(\n",
    "                pythia70m,\n",
    "                circuit,\n",
    "                tokens,\n",
    "                trg_idx,\n",
    "                trg,\n",
    "                submodules,\n",
    "                feat_dicts,\n",
    "                ablation_fn=ablation_fn,\n",
    "                thresholds = thresholds,\n",
    "                handle_errors='resid_only'\n",
    "            )\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "from scipy import interpolate\n",
    "import math\n",
    "\n",
    "# plot faithfulness results\n",
    "fig = go.Figure()\n",
    "\n",
    "colors = {\n",
    "    'features' : 'blue',\n",
    "    'features_wo_errs' : 'red',\n",
    "    'features_wo_some_errs' : 'green',\n",
    "    'neurons' : 'purple',\n",
    "    # 'random_features' : 'black'\n",
    "}\n",
    "\n",
    "y_min = 0\n",
    "y_max = 1\n",
    "for setting, subouts in outs.items():\n",
    "    x_min = max([min(subouts[t]['n_nodes'] for t in thresholds)]) + 1\n",
    "    x_max = min([max(subouts[t]['n_nodes'] for t in thresholds)]) - 1\n",
    "    fs = {\n",
    "        \"ioi\" : interpolate.interp1d([subouts[t]['n_nodes'] for t in thresholds], [subouts[t]['faithfulness'] for t in thresholds])\n",
    "    }\n",
    "    xs = torch.logspace(math.log10(x_min), math.log10(x_max), 100, 10).tolist()\n",
    "\n",
    "    fig.add_trace(go.Scatter(\n",
    "        x = [subouts[t]['n_nodes'] for t in thresholds],\n",
    "        y = [subouts[t]['faithfulness'] for t in thresholds],\n",
    "        mode='lines', line=dict(color=colors[setting]), opacity=0.17, showlegend=False\n",
    "    ))\n",
    "\n",
    "    y_min = min(y_min, min([subouts[t]['faithfulness'] for t in thresholds]))\n",
    "    y_max = max(y_max, max([subouts[t]['faithfulness'] for t in thresholds]))\n",
    "\n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=xs,\n",
    "        y=[ sum([f(x) for f in fs.values()]) / len(fs) for x in xs ],\n",
    "        mode='lines', line=dict(color=colors[setting]), name=setting\n",
    "    ))\n",
    "\n",
    "fig.update_xaxes(type=\"log\", range=[math.log10(x_min), math.log10(x_max)])\n",
    "fig.update_yaxes(range=[y_min, min(y_max, 2)])\n",
    "\n",
    "fig.update_layout(\n",
    "    xaxis_title='Nodes',\n",
    "    yaxis_title='Faithfulness',\n",
    "    width=800,\n",
    "    height=375,\n",
    "    # set white background color\n",
    "    plot_bgcolor='rgba(0,0,0,0)',\n",
    "    # add grey gridlines\n",
    "    yaxis=dict(gridcolor='rgb(200,200,200)',mirror=True,ticks='outside',showline=True),\n",
    "    xaxis=dict(gridcolor='rgb(200,200,200)', mirror=True, ticks='outside', showline=True),\n",
    "\n",
    ")\n",
    "\n",
    "# fig.show()\n",
    "fig.write_image('faithfulness.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[-2.2691e-01, -1.6962e+00, -1.8850e-01,  ...,  6.4711e-01,\n",
      "          -3.8752e-01,  1.3589e+00],\n",
      "         [-2.5375e-01,  1.3514e+00,  3.0055e-01,  ..., -1.1559e+00,\n",
      "          -2.8087e+00, -1.4625e+00],\n",
      "         [-2.1552e+00, -2.8397e-01,  8.4284e-01,  ...,  2.9232e-01,\n",
      "           3.0702e+00, -8.0031e-02],\n",
      "         ...,\n",
      "         [-2.2931e-01, -5.9985e-01, -1.1636e-05,  ...,  9.8394e-01,\n",
      "           1.7133e+00,  4.3503e-01],\n",
      "         [ 8.7894e-01, -2.1109e+00, -6.4177e-02,  ...,  6.2285e-01,\n",
      "           2.2886e+00, -8.0125e-01],\n",
      "         [ 1.3931e-01,  5.7666e-01, -4.5900e-01,  ..., -1.6816e+00,\n",
      "           8.1921e-01,  4.8675e-01]]])\n",
      "tensor([[[-0.4146, -0.2972,  0.1776,  ...,  0.3818,  0.2675,  0.0839],\n",
      "         [ 0.3111, -0.2078, -0.5653,  ...,  0.3336, -0.8643, -0.1204],\n",
      "         [-0.0254, -0.2516, -0.0075,  ..., -0.2861,  0.4456, -0.0099],\n",
      "         ...,\n",
      "         [ 0.1156,  0.2376,  0.4926,  ..., -0.0144,  0.3548,  0.1635],\n",
      "         [-0.3408,  0.0510, -0.3139,  ..., -0.0205,  0.1056, -0.1602],\n",
      "         [-0.2414,  0.3628, -0.3043,  ..., -0.3020,  0.2943, -0.2717]]])\n"
     ]
    }
   ],
   "source": [
    "t1 = torch.randn(10, 16, 512)\n",
    "t2 = ablation_fn(t1)\n",
    "\n",
    "print(t1[0:1])\n",
    "print(t2[0:1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
