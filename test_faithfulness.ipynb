{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ConnardMcGregoire\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "parent_dir = os.path.abspath('..')\n",
    "sys.path.append(parent_dir)\n",
    "\n",
    "from nnsight import LanguageModel\n",
    "from activation_utils import SparseAct\n",
    "import torch as t\n",
    "import plotly.graph_objects as go\n",
    "from loading_utils import load_examples\n",
    "from dictionary_learning import AutoEncoder\n",
    "from dictionary_learning.dictionary import IdentityDict\n",
    "from ablation import run_with_ablations\n",
    "from scipy import interpolate\n",
    "import math\n",
    "from statistics import stdev\n",
    "\n",
    "from circuit import get_circuit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ConnardMcGregoire\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\huggingface_hub\\file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "device = 'cuda:0'\n",
    "DEVICE = 'cuda:0'\n",
    "model = LanguageModel('EleutherAI/pythia-70m-deduped', device_map=device, dispatch=True)\n",
    "\n",
    "start_layer = 2 # explain the model starting here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load submodules\n",
    "submodules = []\n",
    "if start_layer < 0: submodules.append(model.gpt_neox.embed_in)\n",
    "for i in range(start_layer, len(model.gpt_neox.layers)):\n",
    "    submodules.extend([\n",
    "        model.gpt_neox.layers[i].attention,\n",
    "        model.gpt_neox.layers[i].mlp,\n",
    "        model.gpt_neox.layers[i]\n",
    "    ])\n",
    "\n",
    "submod_names = {\n",
    "    model.gpt_neox.embed_in : 'embed'\n",
    "}\n",
    "for i in range(len(model.gpt_neox.layers)):\n",
    "    submod_names[model.gpt_neox.layers[i].attention] = f'attn_{i}'\n",
    "    submod_names[model.gpt_neox.layers[i].mlp] = f'mlp_{i}'\n",
    "    submod_names[model.gpt_neox.layers[i]] = f'resid_{i}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dictionaries\n",
    "dict_id = 10\n",
    "\n",
    "activation_dim = 512\n",
    "expansion_factor = 64\n",
    "dict_size = expansion_factor * activation_dim\n",
    "\n",
    "feat_dicts = {}\n",
    "ae = AutoEncoder(activation_dim, dict_size).to(device)\n",
    "ae.load_state_dict(t.load(f\"C:/Users/ConnardMcGregoire/Documents/MI_Internship/feature-circuits/dictionary_learning/dictionaires/pythia-70m-deduped/embed/ae.pt\", map_location=device))\n",
    "feat_dicts[model.gpt_neox.embed_in] = ae\n",
    "\n",
    "d_model = activation_dim\n",
    "dict_size = d_model * expansion_factor\n",
    "\n",
    "for layer in range(len(model.gpt_neox.layers)):\n",
    "    ae = AutoEncoder(d_model, dict_size).to(device)\n",
    "    ae.load_state_dict(t.load(f\"C:/Users/ConnardMcGregoire/Documents/MI_Internship/feature-circuits/dictionary_learning/dictionaires/pythia-70m-deduped/resid_out_layer{layer}/ae.pt\", map_location=device))\n",
    "    feat_dicts[model.gpt_neox.layers[layer]] = ae\n",
    "\n",
    "    ae = AutoEncoder(d_model, dict_size).to(device)\n",
    "    ae.load_state_dict(t.load(f\"C:/Users/ConnardMcGregoire/Documents/MI_Internship/feature-circuits/dictionary_learning/dictionaires/pythia-70m-deduped/attn_out_layer{layer}/ae.pt\", map_location=device))\n",
    "    feat_dicts[model.gpt_neox.layers[layer].attention] = ae\n",
    "\n",
    "    ae = AutoEncoder(d_model, dict_size).to(device)\n",
    "    ae.load_state_dict(t.load(f\"C:/Users/ConnardMcGregoire/Documents/MI_Internship/feature-circuits/dictionary_learning/dictionaires/pythia-70m-deduped/mlp_out_layer{layer}/ae.pt\", map_location=device))\n",
    "    feat_dicts[model.gpt_neox.layers[layer].mlp] = ae\n",
    "\n",
    "neuron_dicts = {\n",
    "    submod : IdentityDict(activation_dim).to(device) for submod in submodules\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "pythia70m = model\n",
    "\n",
    "pythia70m_embed = pythia70m.gpt_neox.embed_in\n",
    "\n",
    "pythia70m_resids= []\n",
    "pythia70m_attns = []\n",
    "pythia70m_mlps = []\n",
    "for layer in range(len(pythia70m.gpt_neox.layers)):\n",
    "    pythia70m_resids.append(pythia70m.gpt_neox.layers[layer])\n",
    "    pythia70m_attns.append(pythia70m.gpt_neox.layers[layer].attention)\n",
    "    pythia70m_mlps.append(pythia70m.gpt_neox.layers[layer].mlp)\n",
    "    \n",
    "dictionaries = {}\n",
    "\n",
    "d_model = 512\n",
    "dict_size = 32768\n",
    "\n",
    "path = \"C:/Users/ConnardMcGregoire/Documents/MI_Internship/feature-circuits/dictionary_learning/dictionaires/pythia-70m-deduped/\"\n",
    "\n",
    "ae = AutoEncoder(d_model, dict_size).to(DEVICE)\n",
    "ae.load_state_dict(t.load(path + f\"embed/ae.pt\", map_location=DEVICE))\n",
    "dictionaries[pythia70m_embed] = ae\n",
    "\n",
    "\n",
    "for layer in range(len(pythia70m.gpt_neox.layers)):\n",
    "    ae = AutoEncoder(d_model, dict_size).to(DEVICE)\n",
    "    ae.load_state_dict(t.load(path + f\"resid_out_layer{layer}/ae.pt\", map_location=DEVICE))\n",
    "    dictionaries[pythia70m_resids[layer]] = ae\n",
    "\n",
    "    ae = AutoEncoder(d_model, dict_size).to(DEVICE)\n",
    "    ae.load_state_dict(t.load(path + f\"attn_out_layer{layer}/ae.pt\", map_location=DEVICE))\n",
    "    dictionaries[pythia70m_attns[layer]] = ae\n",
    "\n",
    "    ae = AutoEncoder(d_model, dict_size).to(DEVICE)\n",
    "    ae.load_state_dict(t.load(path + f\"mlp_out_layer{layer}/ae.pt\", map_location=DEVICE))\n",
    "    dictionaries[pythia70m_mlps[layer]] = ae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def metric_fn_v1(model, trg=None):\n",
    "    \"\"\"\n",
    "    default : return the logit\n",
    "    \"\"\"\n",
    "    if trg is None:\n",
    "        raise ValueError(\"trg must be provided\")\n",
    "    logits = model.embed_out.output[:,-1,:]\n",
    "    return logits[0, trg[0]] - logits[0, trg[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean = \"When Mary and John went to the store, John gave a drink to\"\n",
    "patch = \"When Mary and John went to the store, Alice gave a drink to\"\n",
    "trg = \" Mary\"\n",
    "trg_idx = t.tensor(pythia70m.tokenizer.encode(trg)[0], device=DEVICE)\n",
    "patch_trg_idx = t.tensor([253], device=DEVICE) # the"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a GPTNeoXTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    }
   ],
   "source": [
    "circuit = get_circuit(\n",
    "    clean, patch,\n",
    "    model,\n",
    "    pythia70m_embed, pythia70m_attns, pythia70m_mlps, pythia70m_resids, dictionaries,\n",
    "    metric_fn_v1, {\"trg\": (trg_idx, patch_trg_idx)}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 50304])\n",
      "0.1829976737499237\n",
      "253\n",
      " the\n",
      "0.07211925834417343\n",
      "617\n",
      " her\n",
      "0.05171777307987213\n",
      "731\n",
      " them\n",
      "0.03711021691560745\n",
      "6393\n",
      " Mary\n",
      "0.03526845946907997\n",
      "779\n",
      " him\n",
      "0.03157972916960716\n",
      "16922\n",
      " Alice\n",
      "0.0294966921210289\n",
      "247\n",
      " a\n",
      "0.011895938776433468\n",
      "5332\n",
      " Jack\n",
      "0.011458381079137325\n",
      "616\n",
      " their\n",
      "0.008285464718937874\n",
      "521\n",
      " his\n"
     ]
    }
   ],
   "source": [
    "with model.trace(patch):\n",
    "    logits = model.output.save()\n",
    "\n",
    "print(logits[0][:, -1, :].shape)\n",
    "logits = logits[0][:, -1, :].squeeze()\n",
    "perm = t.argsort(logits, descending=True)\n",
    "p = t.softmax(logits, dim=-1)\n",
    "for i in range(10):\n",
    "    print(p[perm[i].item()].item())\n",
    "    print(perm[i].item())\n",
    "    print(pythia70m.tokenizer.decode([perm[i].item()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use mean ablation\n",
    "ablation_fn = lambda x: x.mean(dim=0).expand_as(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get m(C) for the circuit obtained by thresholding nodes with the given threshold\n",
    "def get_fcs(\n",
    "    model,\n",
    "    circuit,\n",
    "    submodules,\n",
    "    dictionaries,\n",
    "    ablation_fn,\n",
    "    thresholds,\n",
    "    handle_errors = 'default', # also 'remove' or 'resid_only'\n",
    "):\n",
    "    clean_inputs = clean\n",
    "    clean_answer_idxs = trg_idx\n",
    "    patch_inputs = patch\n",
    "    patch_answer_idxs = patch_trg_idx\n",
    "\n",
    "    def metric_fn(model):\n",
    "        return (\n",
    "            - t.gather(model.embed_out.output[:,-1,:], dim=-1, index=patch_answer_idxs.view(-1, 1)).squeeze(-1) + \\\n",
    "            t.gather(model.embed_out.output[:,-1,:], dim=-1, index=clean_answer_idxs.view(-1, 1)).squeeze(-1)\n",
    "        )\n",
    "    \n",
    "    circuit = circuit[0]\n",
    "\n",
    "    with t.no_grad():\n",
    "        out = {}\n",
    "\n",
    "        # get F(M)\n",
    "        with model.trace(clean_inputs):\n",
    "            metric = metric_fn(model).save()\n",
    "        fm = metric.value.mean().item()\n",
    "\n",
    "        out['fm'] = fm\n",
    "\n",
    "        # get m(∅)\n",
    "        fempty = run_with_ablations(\n",
    "            clean_inputs,\n",
    "            patch_inputs,\n",
    "            model,\n",
    "            submodules,\n",
    "            dictionaries,\n",
    "            nodes = {\n",
    "                submod : SparseAct(\n",
    "                    act=t.zeros(dict_size, dtype=t.bool), \n",
    "                    resc=t.zeros(1, dtype=t.bool)).to(device)\n",
    "                for submod in submodules\n",
    "            },\n",
    "            metric_fn=metric_fn,\n",
    "            ablation_fn=ablation_fn,\n",
    "        ).mean().item()\n",
    "        out['fempty'] = fempty\n",
    "\n",
    "        for threshold in thresholds:\n",
    "            out[threshold] = {}\n",
    "            nodes = {\n",
    "                submod : circuit[submod_names[submod]].abs() > threshold for submod in submodules\n",
    "            }\n",
    "\n",
    "            if handle_errors == 'remove':\n",
    "                for k in nodes: nodes[k].resc = t.zeros_like(nodes[k].resc, dtype=t.bool)\n",
    "            elif handle_errors == 'resid_only':\n",
    "                for k in nodes:\n",
    "                    if k not in model.gpt_neox.layers: nodes[k].resc = t.zeros_like(nodes[k].resc, dtype=t.bool)\n",
    "\n",
    "            n_nodes = sum([n.act.sum() + n.resc.sum() for n in nodes.values()]).item()\n",
    "            out[threshold]['n_nodes'] = n_nodes\n",
    "            \n",
    "            out[threshold]['fc'] = run_with_ablations(\n",
    "                clean_inputs,\n",
    "                patch_inputs,\n",
    "                model,\n",
    "                submodules,\n",
    "                dictionaries,\n",
    "                nodes=nodes,\n",
    "                metric_fn=metric_fn,\n",
    "                ablation_fn=ablation_fn,\n",
    "            ).mean().item()\n",
    "            out[threshold]['fccomp'] = run_with_ablations(\n",
    "                clean_inputs,\n",
    "                patch_inputs,\n",
    "                model,\n",
    "                submodules,\n",
    "                dictionaries,\n",
    "                nodes=nodes,\n",
    "                metric_fn=metric_fn,\n",
    "                ablation_fn=ablation_fn,\n",
    "                complement=True\n",
    "            ).mean().item()\n",
    "            out[threshold]['faithfulness'] = (out[threshold]['fc'] - fempty) / (fm - fempty)\n",
    "            out[threshold]['completeness'] = (out[threshold]['fccomp'] - fempty) / (fm - fempty)\n",
    "    \n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#thresholds = [0.001, 0.002, 0.004, 0.008, 0.016, 0.032, 0.064, 0.128, 0.256, 0.512]\n",
    "thresholds = t.logspace(-4, 0, 15, 10).tolist()\n",
    "outs = {\n",
    "    'features' :\n",
    "        get_fcs(\n",
    "            model,\n",
    "            circuit,\n",
    "            submodules,\n",
    "            feat_dicts,\n",
    "            ablation_fn=ablation_fn,\n",
    "            thresholds = thresholds,\n",
    "        ),\n",
    "    'features_wo_errs' :\n",
    "        get_fcs(\n",
    "            model,\n",
    "            circuit,\n",
    "            submodules,\n",
    "            feat_dicts,\n",
    "            ablation_fn=ablation_fn,\n",
    "            thresholds = thresholds,\n",
    "            handle_errors='remove'\n",
    "        ),\n",
    "    'features_wo_some_errs' :\n",
    "        get_fcs(\n",
    "            model,\n",
    "            circuit,\n",
    "            submodules,\n",
    "            feat_dicts,\n",
    "            ablation_fn=ablation_fn,\n",
    "            thresholds = thresholds,\n",
    "            handle_errors='resid_only'\n",
    "        )\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot faithfulness results\n",
    "fig = go.Figure()\n",
    "\n",
    "colors = {\n",
    "    'features' : 'blue',\n",
    "    'features_wo_errs' : 'red',\n",
    "    'features_wo_some_errs' : 'green',\n",
    "    'neurons' : 'purple',\n",
    "    # 'random_features' : 'black'\n",
    "}\n",
    "\n",
    "for setting, subouts in outs.items():\n",
    "    x_min = max([min(subouts[t]['n_nodes'] for t in thresholds)]) + 1\n",
    "    x_max = min([max(subouts[t]['n_nodes'] for t in thresholds)]) - 1\n",
    "    fs = {\n",
    "        \"ioi\" : interpolate.interp1d([subouts[t]['n_nodes'] for t in thresholds], [subouts[t]['faithfulness'] for t in thresholds])\n",
    "    }\n",
    "    xs = t.logspace(math.log10(x_min), math.log10(x_max), 100, 10).tolist()\n",
    "\n",
    "    fig.add_trace(go.Scatter(\n",
    "        x = [subouts[t]['n_nodes'] for t in thresholds],\n",
    "        y = [subouts[t]['faithfulness'] for t in thresholds],\n",
    "        mode='lines', line=dict(color=colors[setting]), opacity=0.17, showlegend=False\n",
    "    ))\n",
    "\n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=xs,\n",
    "        y=[ sum([f(x) for f in fs.values()]) / len(fs) for x in xs ],\n",
    "        mode='lines', line=dict(color=colors[setting]), name=setting\n",
    "    ))\n",
    "\n",
    "fig.update_xaxes(range=(0, 1700))\n",
    "fig.update_yaxes(range=(0, 1.1))\n",
    "\n",
    "fig.update_layout(\n",
    "    xaxis_title='Nodes',\n",
    "    yaxis_title='Faithfulness',\n",
    "    width=800,\n",
    "    height=375,\n",
    "    # set white background color\n",
    "    plot_bgcolor='rgba(0,0,0,0)',\n",
    "    # add grey gridlines\n",
    "    yaxis=dict(gridcolor='rgb(200,200,200)',mirror=True,ticks='outside',showline=True),\n",
    "    xaxis=dict(gridcolor='rgb(200,200,200)', mirror=True, ticks='outside', showline=True),\n",
    "\n",
    ")\n",
    "\n",
    "# fig.show()\n",
    "fig.write_image('faithfulness.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot completeness results\n",
    "fig = go.Figure()\n",
    "\n",
    "colors = {\n",
    "    'features' : 'blue',\n",
    "    'features_wo_errs' : 'red',\n",
    "    'features_wo_some_errs' : 'green',\n",
    "    'neurons' : 'purple'\n",
    "}\n",
    "\n",
    "for setting, subouts in outs.items():\n",
    "\n",
    "    x_min = max([min(subouts[dataset][t]['n_nodes'] for t in thresholds) for dataset in datasets]) + 1\n",
    "    x_max = min([max(subouts[dataset][t]['n_nodes'] for t in thresholds) for dataset in datasets]) - 1\n",
    "    fs = {\n",
    "        dataset : interpolate.interp1d([subouts[dataset][t]['n_nodes'] for t in thresholds], [subouts[dataset][t]['completeness'] for t in thresholds])\n",
    "        for dataset in datasets\n",
    "    }\n",
    "    xs = t.logspace(math.log10(x_min), math.log10(x_max), 100, 10).tolist()\n",
    "\n",
    "    for dataset in datasets:\n",
    "        fig.add_trace(go.Scatter(\n",
    "            x = [subouts[dataset][t]['n_nodes'] for t in thresholds],\n",
    "            y = [subouts[dataset][t]['completeness'] for t in thresholds],\n",
    "            mode='lines', line=dict(color=colors[setting]), opacity=0.17, showlegend=False\n",
    "        ))\n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=xs,\n",
    "        y=[ sum([f(x) for f in fs.values()]) / len(fs) for x in xs ],\n",
    "        mode='lines', line=dict(color=colors[setting]), name=setting\n",
    "    ))\n",
    "\n",
    "fig.update_xaxes(range=(0,300))\n",
    "fig.update_yaxes(range=(-.15, 1))\n",
    "\n",
    "fig.update_layout(\n",
    "    xaxis_title='Nodes',\n",
    "    yaxis_title='Faithfulness',\n",
    "    width=800,\n",
    "    height=375,\n",
    "    # set white background color\n",
    "    plot_bgcolor='rgba(0,0,0,0)',\n",
    "    # add grey gridlines\n",
    "    yaxis=dict(gridcolor='rgb(200,200,200)',mirror=True,ticks='outside',showline=True),\n",
    "    xaxis=dict(gridcolor='rgb(200,200,200)', mirror=True, ticks='outside', showline=True),\n",
    ")\n",
    "# fig.show()\n",
    "fig.write_image('completeness.pdf')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
